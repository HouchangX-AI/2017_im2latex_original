[Training.evaluate], 2020-03-25 06:30:04: loss=6.908003807067871, acc=0.03797397225897529
[Training.evaluate], 2020-03-25 06:30:04: 1.64459430882135e-68
[Training.evaluate], 2020-03-25 06:30:04: 0.06552349086853482
[Trainer.py], 2020-03-25 10:58:06: checkpoints/snapshot-01.pt loaded.
[Trainer.py], 2020-03-25 10:58:06: evaluation starts.
[Trainer.py], 2020-03-25 11:00:04: evaluation finished.
[Training.evaluate], 2020-03-25 07:06:32: loss=5.576351165771484, acc=0.11052033285494756
[Training.evaluate], 2020-03-25 07:06:33: 0.007199762937093293
[Training.evaluate], 2020-03-25 07:06:33: 0.15499194847020936
[Trainer.py], 2020-03-25 11:34:38: checkpoints/snapshot-02.pt loaded.
[Trainer.py], 2020-03-25 11:34:38: evaluation starts.
[Trainer.py], 2020-03-25 11:36:32: evaluation finished.
[Training.evaluate], 2020-03-25 07:42:17: loss=5.108554363250732, acc=0.041301457710036946
[Training.evaluate], 2020-03-25 07:42:17: 0.003514289063252584
[Training.evaluate], 2020-03-25 07:42:17: 0.09605464937961805
[Trainer.py], 2020-03-25 12:10:27: checkpoints/snapshot-03.pt loaded.
[Trainer.py], 2020-03-25 12:10:27: evaluation starts.
[Trainer.py], 2020-03-25 12:12:17: evaluation finished.
[Training.evaluate], 2020-03-25 08:16:01: loss=5.4899797439575195, acc=0.08132587869122661
[Training.evaluate], 2020-03-25 08:16:01: 0.013838589308080396
[Training.evaluate], 2020-03-25 08:16:01: 0.16522098306484923
[Trainer.py], 2020-03-25 12:44:10: checkpoints/snapshot-04.pt loaded.
[Trainer.py], 2020-03-25 12:44:10: evaluation starts.
[Trainer.py], 2020-03-25 12:46:01: evaluation finished.
[Training.evaluate], 2020-03-25 08:52:43: loss=5.160572528839111, acc=0.05576131981717904
[Training.evaluate], 2020-03-25 08:52:43: 0.0056739887212210625
[Training.evaluate], 2020-03-25 08:52:43: 0.1229281767955801
[Trainer.py], 2020-03-25 13:20:46: checkpoints/snapshot-05.pt loaded.
[Trainer.py], 2020-03-25 13:20:46: evaluation starts.
[Trainer.py], 2020-03-25 13:22:43: evaluation finished.
[Training.evaluate], 2020-03-25 09:29:37: loss=5.2133965492248535, acc=0.09366322304462106
[Training.evaluate], 2020-03-25 09:29:38: 0.01670947433672025
[Training.evaluate], 2020-03-25 09:29:38: 0.16129032258064513
[Trainer.py], 2020-03-25 13:57:42: checkpoints/snapshot-06.pt loaded.
[Trainer.py], 2020-03-25 13:57:42: evaluation starts.
[Trainer.py], 2020-03-25 13:59:37: evaluation finished.
[Training.evaluate], 2020-03-25 10:06:14: loss=5.373978614807129, acc=0.0900968212692822
[Training.evaluate], 2020-03-25 10:06:15: 0.01557535818632675
[Training.evaluate], 2020-03-25 10:06:15: 0.16565562295846947
[Trainer.py], 2020-03-25 14:34:16: checkpoints/snapshot-07.pt loaded.
[Trainer.py], 2020-03-25 14:34:16: evaluation starts.
[Trainer.py], 2020-03-25 14:36:14: evaluation finished.
[Training.evaluate], 2020-03-25 11:57:00: loss=4.945006370544434, acc=0.07007044407994542
[Training.evaluate], 2020-03-25 11:57:00: 0.027940032506096
[Training.evaluate], 2020-03-25 11:57:00: 0.15547397970200816
[Trainer.py], 2020-03-25 16:25:10: checkpoints/snapshot-08.pt loaded.
[Trainer.py], 2020-03-25 16:25:10: evaluation starts.
[Trainer.py], 2020-03-25 16:27:00: evaluation finished.
[Trainer.py], 2020-03-25 10:19:40: start training one epoch
[Trainer.py], 2020-03-25 10:26:57: Batch 0: loss=5.5883073806762695, acc=0.004610419548178884, lr=0.001
[Trainer.py], 2020-03-25 10:35:30: Batch 10: loss=3.8844635486602783, acc=0.2904191616766467, lr=0.001
[Trainer.py], 2020-03-25 10:41:21: Batch 20: loss=3.373185873031616, acc=0.32871125611745516, lr=0.001
[Trainer.py], 2020-03-25 10:46:25: Batch 30: loss=3.4372363090515137, acc=0.3155080213903743, lr=0.001
[Trainer.py], 2020-03-25 10:50:25: Batch 40: loss=3.082362174987793, acc=0.3477124183006536, lr=0.001
[Trainer.py], 2020-03-25 10:54:03: Batch 50: loss=3.2217137813568115, acc=0.356140350877193, lr=0.001
[Trainer.py], 2020-03-25 10:57:33: Batch 60: loss=3.329338550567627, acc=0.3654970760233918, lr=0.001
[Trainer.py], 2020-03-25 10:58:01: Epoch finished, loss=3.471767993200393 acc=0.32129849031543495, lr=0.001
[Trainer.py], 2020-03-25 10:58:01: training one epoch finished.
[Trainer.py], 2020-03-25 10:58:01: Epoch 1 saved.
[Trainer.py], 2020-03-25 11:00:04: start training one epoch
[Trainer.py], 2020-03-25 11:02:11: Batch 0: loss=4.209315299987793, acc=0.21645919778699863, lr=0.001
[Trainer.py], 2020-03-25 11:10:50: Batch 10: loss=3.241316080093384, acc=0.35568862275449104, lr=0.001
[Trainer.py], 2020-03-25 11:16:58: Batch 20: loss=3.065516710281372, acc=0.367047308319739, lr=0.001
[Trainer.py], 2020-03-25 11:22:03: Batch 30: loss=3.051797866821289, acc=0.39144385026737966, lr=0.001
[Trainer.py], 2020-03-25 11:26:34: Batch 40: loss=2.82127046585083, acc=0.41830065359477125, lr=0.001
[Trainer.py], 2020-03-25 11:30:36: Batch 50: loss=3.1313352584838867, acc=0.39473684210526316, lr=0.001
[Trainer.py], 2020-03-25 11:34:06: Batch 60: loss=3.0660650730133057, acc=0.4298245614035088, lr=0.001
[Trainer.py], 2020-03-25 11:34:35: Epoch finished, loss=3.0967481287698897 acc=0.3825901167918775, lr=0.001
[Trainer.py], 2020-03-25 11:34:35: training one epoch finished.
[Trainer.py], 2020-03-25 11:34:35: Epoch 2 saved.
[Trainer.py], 2020-03-25 11:36:33: start training one epoch
[Trainer.py], 2020-03-25 11:38:38: Batch 0: loss=3.274667263031006, acc=0.34071000461041956, lr=0.001
[Trainer.py], 2020-03-25 11:47:35: Batch 10: loss=3.0012478828430176, acc=0.38682634730538923, lr=0.001
[Trainer.py], 2020-03-25 11:53:52: Batch 20: loss=2.881537437438965, acc=0.4061990212071778, lr=0.001
[Trainer.py], 2020-03-25 11:58:58: Batch 30: loss=2.896698474884033, acc=0.40962566844919784, lr=0.001
[Trainer.py], 2020-03-25 12:03:09: Batch 40: loss=2.6074249744415283, acc=0.46405228758169936, lr=0.001
[Trainer.py], 2020-03-25 12:06:47: Batch 50: loss=2.978161573410034, acc=0.4192982456140351, lr=0.001
[Trainer.py], 2020-03-25 12:09:59: Batch 60: loss=3.1890640258789062, acc=0.3888888888888889, lr=0.001
[Trainer.py], 2020-03-25 12:10:24: Epoch finished, loss=2.895392936373514 acc=0.41445131680832137, lr=0.001
[Trainer.py], 2020-03-25 12:10:24: training one epoch finished.
[Trainer.py], 2020-03-25 12:10:24: Epoch 3 saved.
[Trainer.py], 2020-03-25 12:12:17: start training one epoch
[Trainer.py], 2020-03-25 12:14:16: Batch 0: loss=3.3063230514526367, acc=0.338865836791148, lr=0.001
[Trainer.py], 2020-03-25 12:22:10: Batch 10: loss=2.9465246200561523, acc=0.40119760479041916, lr=0.001
[Trainer.py], 2020-03-25 12:27:58: Batch 20: loss=2.8362443447113037, acc=0.41272430668841764, lr=0.001
[Trainer.py], 2020-03-25 12:32:50: Batch 30: loss=2.8803634643554688, acc=0.41711229946524064, lr=0.001
[Trainer.py], 2020-03-25 12:36:56: Batch 40: loss=2.575632333755493, acc=0.4588235294117647, lr=0.001
[Trainer.py], 2020-03-25 12:40:30: Batch 50: loss=2.845430374145508, acc=0.45087719298245615, lr=0.001
[Trainer.py], 2020-03-25 12:43:42: Batch 60: loss=2.993612051010132, acc=0.40350877192982454, lr=0.001
[Trainer.py], 2020-03-25 12:44:08: Epoch finished, loss=2.877213508363754 acc=0.41391762217580674, lr=0.001
[Trainer.py], 2020-03-25 12:44:08: training one epoch finished.
[Trainer.py], 2020-03-25 12:44:08: Epoch 4 saved.
[Trainer.py], 2020-03-25 12:46:01: start training one epoch
[Trainer.py], 2020-03-25 12:48:02: Batch 0: loss=2.991185188293457, acc=0.38381742738589214, lr=0.001
[Trainer.py], 2020-03-25 12:56:02: Batch 10: loss=2.806370258331299, acc=0.4215568862275449, lr=0.001
[Trainer.py], 2020-03-25 13:02:15: Batch 20: loss=2.8138327598571777, acc=0.42088091353996737, lr=0.001
[Trainer.py], 2020-03-25 13:07:52: Batch 30: loss=2.8593597412109375, acc=0.41497326203208557, lr=0.001
[Trainer.py], 2020-03-25 13:12:30: Batch 40: loss=2.508066415786743, acc=0.4627450980392157, lr=0.001
[Trainer.py], 2020-03-25 13:16:37: Batch 50: loss=2.8029978275299072, acc=0.44912280701754387, lr=0.001
[Trainer.py], 2020-03-25 13:20:15: Batch 60: loss=3.0424156188964844, acc=0.3830409356725146, lr=0.001
[Trainer.py], 2020-03-25 13:20:42: Epoch finished, loss=2.7493765581221807 acc=0.4356172312761524, lr=0.001
[Trainer.py], 2020-03-25 13:20:42: training one epoch finished.
[Trainer.py], 2020-03-25 13:20:43: Epoch 5 saved.
[Trainer.py], 2020-03-25 13:22:43: start training one epoch
[Trainer.py], 2020-03-25 13:24:56: Batch 0: loss=3.021601676940918, acc=0.3817427385892116, lr=0.0005
[Trainer.py], 2020-03-25 13:33:29: Batch 10: loss=2.9150068759918213, acc=0.3970059880239521, lr=0.0005
[Trainer.py], 2020-03-25 13:39:39: Batch 20: loss=2.698293685913086, acc=0.42495921696574224, lr=0.0005
[Trainer.py], 2020-03-25 13:44:48: Batch 30: loss=2.755405902862549, acc=0.43422459893048126, lr=0.0005
[Trainer.py], 2020-03-25 13:49:28: Batch 40: loss=2.789628744125366, acc=0.40522875816993464, lr=0.0005
[Trainer.py], 2020-03-25 13:53:34: Batch 50: loss=2.7440245151519775, acc=0.4614035087719298, lr=0.0005
[Trainer.py], 2020-03-25 13:57:11: Batch 60: loss=2.958569049835205, acc=0.40350877192982454, lr=0.0005
[Trainer.py], 2020-03-25 13:57:39: Epoch finished, loss=2.7485045819055465 acc=0.42975774832238295, lr=0.0005
[Trainer.py], 2020-03-25 13:57:39: training one epoch finished.
[Trainer.py], 2020-03-25 13:57:39: Epoch 6 saved.
[Trainer.py], 2020-03-25 13:59:38: start training one epoch
[Trainer.py], 2020-03-25 14:01:43: Batch 0: loss=2.8614938259124756, acc=0.4094052558782849, lr=0.0005
[Trainer.py], 2020-03-25 14:10:14: Batch 10: loss=2.787599802017212, acc=0.4101796407185629, lr=0.0005
[Trainer.py], 2020-03-25 14:16:28: Batch 20: loss=2.667581081390381, acc=0.43230016313213704, lr=0.0005
[Trainer.py], 2020-03-25 14:21:36: Batch 30: loss=2.524787664413452, acc=0.4716577540106952, lr=0.0005
[Trainer.py], 2020-03-25 14:26:12: Batch 40: loss=2.484856128692627, acc=0.47320261437908495, lr=0.0005
[Trainer.py], 2020-03-25 14:30:15: Batch 50: loss=2.7826480865478516, acc=0.45263157894736844, lr=0.0005
[Trainer.py], 2020-03-25 14:33:45: Batch 60: loss=3.1774535179138184, acc=0.36257309941520466, lr=0.0005
[Trainer.py], 2020-03-25 14:34:13: Epoch finished, loss=2.6827863700806147 acc=0.43958899686211117, lr=0.0005
[Trainer.py], 2020-03-25 14:34:13: training one epoch finished.
[Trainer.py], 2020-03-25 14:34:13: Epoch 7 saved.
[Trainer.py], 2020-03-25 14:36:15: start training one epoch
[Trainer.py], 2020-03-25 14:38:27: Batch 0: loss=2.862604856491089, acc=0.41124942369755646, lr=0.0005
[Trainer.py], 2020-03-25 14:47:10: Batch 10: loss=2.8792574405670166, acc=0.39461077844311376, lr=0.0005
[Trainer.py], 2020-03-25 14:53:26: Batch 20: loss=2.624661684036255, acc=0.4526916802610114, lr=0.0005
[Trainer.py], 2020-03-25 14:58:27: Batch 30: loss=2.7773489952087402, acc=0.413903743315508, lr=0.0005
[Trainer.py], 2020-03-25 15:02:43: Batch 40: loss=2.505566358566284, acc=0.4588235294117647, lr=0.0005
[Trainer.py], 2020-03-25 16:21:30: Batch 50: loss=2.7924652099609375, acc=0.4245614035087719, lr=0.0005
[Trainer.py], 2020-03-25 16:24:42: Batch 60: loss=3.196340322494507, acc=0.36257309941520466, lr=0.0005
[Trainer.py], 2020-03-25 16:25:08: Epoch finished, loss=2.756632124620771 acc=0.42563453797030126, lr=0.0005
[Trainer.py], 2020-03-25 16:25:08: training one epoch finished.
[Trainer.py], 2020-03-25 16:25:08: Epoch 8 saved.
[Trainer.py], 2020-03-25 16:27:00: start training one epoch
[Trainer.py], 2020-03-25 16:29:00: Batch 0: loss=2.929619312286377, acc=0.3930382664822499, lr=0.0005[Training.evaluate], 2020-03-25 12:30:01: loss=5.192016124725342, acc=0.07624546438573278
[Training.evaluate], 2020-03-25 12:30:02: 0.028204493826177072
[Training.evaluate], 2020-03-25 12:30:02: 0.2265455531453362
[Trainer.py], 2020-03-25 16:58:11: checkpoints/snapshot-09.pt loaded.
[Trainer.py], 2020-03-25 16:58:11: evaluation starts.
[Trainer.py], 2020-03-25 17:00:01: evaluation finished.
[Training.evaluate], 2020-03-25 13:02:49: loss=4.7326130867004395, acc=0.07486193741200951
[Training.evaluate], 2020-03-25 13:02:49: 2.422224394488122e-64
[Training.evaluate], 2020-03-25 13:02:49: 0.194304435483871
[Trainer.py], 2020-03-25 17:30:59: checkpoints/snapshot-10.pt loaded.
[Trainer.py], 2020-03-25 17:30:59: evaluation starts.
[Trainer.py], 2020-03-25 17:32:49: evaluation finished.
[Training.evaluate], 2020-03-25 13:35:13: loss=5.056278705596924, acc=0.09730212518603475
[Training.evaluate], 2020-03-25 13:35:13: 0.01490945058562592
[Training.evaluate], 2020-03-25 13:35:13: 0.16414122564753308
[Trainer.py], 2020-03-25 18:03:23: checkpoints/snapshot-11.pt loaded.
[Trainer.py], 2020-03-25 18:03:23: evaluation starts.
[Trainer.py], 2020-03-25 18:05:13: evaluation finished.
[Training.evaluate], 2020-03-25 14:07:49: loss=4.653914451599121, acc=0.11563240836921948
[Training.evaluate], 2020-03-25 14:07:49: 0.013429866767994713
[Training.evaluate], 2020-03-25 14:07:49: 0.2152756390514321
[Trainer.py], 2020-03-25 18:35:59: checkpoints/snapshot-12.pt loaded.
[Trainer.py], 2020-03-25 18:35:59: evaluation starts.
[Trainer.py], 2020-03-25 18:37:49: evaluation finished.
[Training.evaluate], 2020-03-25 14:40:22: loss=5.000229358673096, acc=0.11298273186355909
[Training.evaluate], 2020-03-25 14:40:23: 0.01965839081821018
[Training.evaluate], 2020-03-25 14:40:23: 0.2052774234693877
[Trainer.py], 2020-03-25 19:08:33: checkpoints/snapshot-13.pt loaded.
[Trainer.py], 2020-03-25 19:08:33: evaluation starts.
[Trainer.py], 2020-03-25 19:10:22: evaluation finished.
[Training.evaluate], 2020-03-25 15:12:57: loss=4.761708736419678, acc=0.0951142841564347
[Training.evaluate], 2020-03-25 15:12:57: 0.021156366667203774
[Training.evaluate], 2020-03-25 15:12:57: 0.22760416666666672
[Trainer.py], 2020-03-25 19:41:07: checkpoints/snapshot-14.pt loaded.
[Trainer.py], 2020-03-25 19:41:07: evaluation starts.
[Trainer.py], 2020-03-25 19:42:57: evaluation finished.
[Training.evaluate], 2020-03-25 15:45:22: loss=4.8060712814331055, acc=0.09981181767506724
[Training.evaluate], 2020-03-25 15:45:22: 0.031336578531573824
[Training.evaluate], 2020-03-25 15:45:22: 0.2434867299732164
[Trainer.py], 2020-03-25 20:13:33: checkpoints/snapshot-15.pt loaded.
[Trainer.py], 2020-03-25 20:13:33: evaluation starts.
[Trainer.py], 2020-03-25 20:15:22: evaluation finished.
[Training.evaluate], 2020-03-25 16:17:55: loss=4.6342997550964355, acc=0.1159593400931576
[Training.evaluate], 2020-03-25 16:17:55: 0.016772578148155977
[Training.evaluate], 2020-03-25 16:17:55: 0.1814643034619844
[Trainer.py], 2020-03-25 20:46:06: checkpoints/snapshot-16.pt loaded.
[Trainer.py], 2020-03-25 20:46:06: evaluation starts.
[Trainer.py], 2020-03-25 20:47:55: evaluation finished.

[Trainer.py], 2020-03-25 16:36:56: Batch 10: loss=2.8087127208709717, acc=0.4119760479041916, lr=0.0005
[Trainer.py], 2020-03-25 16:42:36: Batch 20: loss=2.5944321155548096, acc=0.4526916802610114, lr=0.0005
[Trainer.py], 2020-03-25 16:47:10: Batch 30: loss=2.5338635444641113, acc=0.4588235294117647, lr=0.0005
[Trainer.py], 2020-03-25 16:51:03: Batch 40: loss=2.552058219909668, acc=0.45751633986928103, lr=0.0005
[Trainer.py], 2020-03-25 16:54:34: Batch 50: loss=2.614656925201416, acc=0.4666666666666667, lr=0.0005
[Trainer.py], 2020-03-25 16:57:43: Batch 60: loss=3.211791515350342, acc=0.3304093567251462, lr=0.0005
[Trainer.py], 2020-03-25 16:58:09: Epoch finished, loss=2.7157667033256048 acc=0.4325588796961463, lr=0.0005
[Trainer.py], 2020-03-25 16:58:09: training one epoch finished.
[Trainer.py], 2020-03-25 16:58:09: Epoch 9 saved.
[Trainer.py], 2020-03-25 17:00:02: start training one epoch
[Trainer.py], 2020-03-25 17:02:01: Batch 0: loss=3.0109920501708984, acc=0.3822037805440295, lr=0.0005
[Trainer.py], 2020-03-25 17:09:53: Batch 10: loss=2.8900227546691895, acc=0.4041916167664671, lr=0.0005
[Trainer.py], 2020-03-25 17:15:31: Batch 20: loss=2.8793439865112305, acc=0.40375203915171287, lr=0.0005
[Trainer.py], 2020-03-25 17:19:56: Batch 30: loss=2.6283133029937744, acc=0.44919786096256686, lr=0.0005
[Trainer.py], 2020-03-25 17:23:49: Batch 40: loss=2.827439785003662, acc=0.40784313725490196, lr=0.0005
[Trainer.py], 2020-03-25 17:27:22: Batch 50: loss=2.759704351425171, acc=0.4263157894736842, lr=0.0005
[Trainer.py], 2020-03-25 17:30:31: Batch 60: loss=2.5573065280914307, acc=0.47076023391812866, lr=0.0005
[Trainer.py], 2020-03-25 17:30:56: Epoch finished, loss=2.8055128890370566 acc=0.41416161775522675, lr=0.0005
[Trainer.py], 2020-03-25 17:30:56: training one epoch finished.
[Trainer.py], 2020-03-25 17:30:56: Epoch 10 saved.
[Trainer.py], 2020-03-25 17:32:49: start training one epoch
[Trainer.py], 2020-03-25 17:34:48: Batch 0: loss=2.964078426361084, acc=0.388427846934071, lr=0.00025
[Trainer.py], 2020-03-25 17:42:36: Batch 10: loss=2.8577518463134766, acc=0.39221556886227543, lr=0.00025
[Trainer.py], 2020-03-25 17:48:02: Batch 20: loss=2.8728554248809814, acc=0.4078303425774878, lr=0.00025
[Trainer.py], 2020-03-25 17:52:24: Batch 30: loss=2.8375861644744873, acc=0.413903743315508, lr=0.00025
[Trainer.py], 2020-03-25 17:56:17: Batch 40: loss=2.7307655811309814, acc=0.4169934640522876, lr=0.00025
[Trainer.py], 2020-03-25 17:59:47: Batch 50: loss=3.068577289581299, acc=0.37719298245614036, lr=0.00025
[Trainer.py], 2020-03-25 18:02:55: Batch 60: loss=2.4944403171539307, acc=0.4678362573099415, lr=0.00025
[Trainer.py], 2020-03-25 18:03:20: Epoch finished, loss=2.744331179157136 acc=0.4249468754571576, lr=0.00025
[Trainer.py], 2020-03-25 18:03:20: training one epoch finished.
[Trainer.py], 2020-03-25 18:03:20: Epoch 11 saved.
[Trainer.py], 2020-03-25 18:05:13: start training one epoch
[Trainer.py], 2020-03-25 18:07:13: Batch 0: loss=3.0553250312805176, acc=0.37505763024435224, lr=0.00025
[Trainer.py], 2020-03-25 18:15:01: Batch 10: loss=2.82951283454895, acc=0.40718562874251496, lr=0.00025
[Trainer.py], 2020-03-25 18:20:35: Batch 20: loss=2.7051432132720947, acc=0.433931484502447, lr=0.00025
[Trainer.py], 2020-03-25 18:25:01: Batch 30: loss=2.6898515224456787, acc=0.4235294117647059, lr=0.00025
[Trainer.py], 2020-03-25 18:28:53: Batch 40: loss=2.620867967605591, acc=0.4366013071895425, lr=0.00025
[Trainer.py], 2020-03-25 18:32:23: Batch 50: loss=3.0813021659851074, acc=0.3631578947368421, lr=0.00025
[Trainer.py], 2020-03-25 18:35:31: Batch 60: loss=2.7175045013427734, acc=0.43859649122807015, lr=0.00025
[Trainer.py], 2020-03-25 18:35:56: Epoch finished, loss=2.7863911333538236 acc=0.4169264324273355, lr=0.00025
[Trainer.py], 2020-03-25 18:35:56: training one epoch finished.
[Trainer.py], 2020-03-25 18:35:56: Epoch 12 saved.
[Trainer.py], 2020-03-25 18:37:49: start training one epoch
[Trainer.py], 2020-03-25 18:39:48: Batch 0: loss=2.9211931228637695, acc=0.39119409866297833, lr=0.00025
[Trainer.py], 2020-03-25 18:47:34: Batch 10: loss=2.853684425354004, acc=0.40119760479041916, lr=0.00025
[Trainer.py], 2020-03-25 18:53:03: Batch 20: loss=2.735504627227783, acc=0.4184339314845024, lr=0.00025
[Trainer.py], 2020-03-25 18:57:35: Batch 30: loss=2.738192319869995, acc=0.41711229946524064, lr=0.00025
[Trainer.py], 2020-03-25 19:01:27: Batch 40: loss=2.684856653213501, acc=0.4235294117647059, lr=0.00025
[Trainer.py], 2020-03-25 19:04:57: Batch 50: loss=2.9231789112091064, acc=0.38421052631578945, lr=0.00025
[Trainer.py], 2020-03-25 19:08:05: Batch 60: loss=2.948169469833374, acc=0.38596491228070173, lr=0.00025
[Trainer.py], 2020-03-25 19:08:30: Epoch finished, loss=2.7366831349948098 acc=0.42369330293458257, lr=0.00025
[Trainer.py], 2020-03-25 19:08:30: training one epoch finished.
[Trainer.py], 2020-03-25 19:08:30: Epoch 13 saved.
[Trainer.py], 2020-03-25 19:10:23: start training one epoch
[Trainer.py], 2020-03-25 19:12:23: Batch 0: loss=2.9097540378570557, acc=0.3953434762563393, lr=0.00025
[Trainer.py], 2020-03-25 19:20:13: Batch 10: loss=2.8066070079803467, acc=0.4101796407185629, lr=0.00025
[Trainer.py], 2020-03-25 19:25:48: Batch 20: loss=2.771291971206665, acc=0.40456769983686786, lr=0.00025
[Trainer.py], 2020-03-25 19:30:10: Batch 30: loss=2.846968412399292, acc=0.39358288770053473, lr=0.00025
[Trainer.py], 2020-03-25 19:34:02: Batch 40: loss=2.788106679916382, acc=0.4300653594771242, lr=0.00025
[Trainer.py], 2020-03-25 19:37:31: Batch 50: loss=2.7659943103790283, acc=0.42280701754385963, lr=0.00025
[Trainer.py], 2020-03-25 19:40:39: Batch 60: loss=2.7777678966522217, acc=0.4093567251461988, lr=0.00025
[Trainer.py], 2020-03-25 19:41:04: Epoch finished, loss=2.785035218038256 acc=0.41499795481668306, lr=0.00025
[Trainer.py], 2020-03-25 19:41:04: training one epoch finished.
[Trainer.py], 2020-03-25 19:41:04: Epoch 14 saved.
[Trainer.py], 2020-03-25 19:42:57: start training one epoch
[Trainer.py], 2020-03-25 19:44:57: Batch 0: loss=2.8651885986328125, acc=0.4020285846011987, lr=0.00025
[Trainer.py], 2020-03-25 19:52:43: Batch 10: loss=2.982567071914673, acc=0.37664670658682636, lr=0.00025
[Trainer.py], 2020-03-25 19:58:12: Batch 20: loss=2.8158087730407715, acc=0.40375203915171287, lr=0.00025
[Trainer.py], 2020-03-25 20:02:34: Batch 30: loss=2.7076961994171143, acc=0.4310160427807487, lr=0.00025
[Trainer.py], 2020-03-25 20:06:26: Batch 40: loss=2.642664909362793, acc=0.4326797385620915, lr=0.00025
[Trainer.py], 2020-03-25 20:09:57: Batch 50: loss=3.011080265045166, acc=0.38070175438596493, lr=0.00025
[Trainer.py], 2020-03-25 20:13:04: Batch 60: loss=2.7923781871795654, acc=0.40058479532163743, lr=0.00025
[Trainer.py], 2020-03-25 20:13:29: Epoch finished, loss=2.7817307880946567 acc=0.41382399271998677, lr=0.00025
[Trainer.py], 2020-03-25 20:13:29: training one epoch finished.
[Trainer.py], 2020-03-25 20:13:30: Epoch 15 saved.
[Trainer.py], 2020-03-25 20:15:22: start training one epoch
[Trainer.py], 2020-03-25 20:17:22: Batch 0: loss=2.9469785690307617, acc=0.3868142000922084, lr=0.000125
[Trainer.py], 2020-03-25 20:25:11: Batch 10: loss=2.946599006652832, acc=0.37425149700598803, lr=0.000125
[Trainer.py], 2020-03-25 20:30:42: Batch 20: loss=2.7441635131835938, acc=0.4257748776508972, lr=0.000125
[Trainer.py], 2020-03-25 20:35:09: Batch 30: loss=2.8702144622802734, acc=0.3732620320855615, lr=0.000125
[Trainer.py], 2020-03-25 20:39:01: Batch 40: loss=2.632617712020874, acc=0.44313725490196076, lr=0.000125
[Trainer.py], 2020-03-25 20:42:30: Batch 50: loss=2.7770140171051025, acc=0.4017543859649123, lr=0.000125
[Trainer.py], 2020-03-25 20:45:37: Batch 60: loss=2.9412899017333984, acc=0.39473684210526316, lr=0.000125
[Trainer.py], 2020-03-25 20:46:02: Epoch finished, loss=2.7627646142528173 acc=0.4160237219871353, lr=0.000125
[Trainer.py], 2020-03-25 20:46:02: training one epoch finished.
[Trainer.py], 2020-03-25 20:46:02: Epoch 16 saved.
[Trainer.py], 2020-03-25 20:47:55: start training one epoch
[Trainer.py], 2020-03-25 20:49:55: Batch 0: loss=2.8682827949523926, acc=0.3978792070078377, lr=0.000125
[Trainer.py], 2020-03-25 20:57:42: Batch 10: loss=2.9658203125, acc=0.37964071856287424, lr=0.000125[Training.evaluate], 2020-03-25 16:50:25: loss=4.84212589263916, acc=0.10082128994416181
[Training.evaluate], 2020-03-25 16:50:25: 0.022710712865103247
[Training.evaluate], 2020-03-25 16:50:25: 0.1978841976008312
[Trainer.py], 2020-03-25 21:18:35: checkpoints/snapshot-17.pt loaded.
[Trainer.py], 2020-03-25 21:18:35: evaluation starts.
[Trainer.py], 2020-03-25 21:20:25: evaluation finished.
[Training.evaluate], 2020-03-25 17:23:02: loss=4.863339900970459, acc=0.09782991607589551
[Training.evaluate], 2020-03-25 17:23:03: 0.0384295635116452
[Training.evaluate], 2020-03-25 17:23:03: 0.23652626811594202
[Trainer.py], 2020-03-25 21:51:13: checkpoints/snapshot-18.pt loaded.
[Trainer.py], 2020-03-25 21:51:13: evaluation starts.
[Trainer.py], 2020-03-25 21:53:02: evaluation finished.
[Training.evaluate], 2020-03-25 17:55:30: loss=4.850208282470703, acc=0.08091861756024436
[Training.evaluate], 2020-03-25 17:55:30: 0.0335712655741735
[Training.evaluate], 2020-03-25 17:55:30: 0.23106423777564722
[Trainer.py], 2020-03-25 22:23:40: checkpoints/snapshot-19.pt loaded.
[Trainer.py], 2020-03-25 22:23:40: evaluation starts.
[Trainer.py], 2020-03-25 22:25:30: evaluation finished.
[Training.evaluate], 2020-03-25 18:27:51: loss=4.8436126708984375, acc=0.0774478278937898
[Training.evaluate], 2020-03-25 18:27:51: 0.02397907169485483
[Training.evaluate], 2020-03-25 18:27:51: 0.22149212867898704
[Trainer.py], 2020-03-25 22:56:02: checkpoints/snapshot-20.pt loaded.
[Trainer.py], 2020-03-25 22:56:02: evaluation starts.
[Trainer.py], 2020-03-25 22:57:51: evaluation finished.
[Training.evaluate], 2020-03-25 19:00:16: loss=4.815723896026611, acc=0.09267229579689044
[Training.evaluate], 2020-03-25 19:00:16: 0.036417947039511504
[Training.evaluate], 2020-03-25 19:00:16: 0.24741602067183466
[Trainer.py], 2020-03-25 23:28:26: checkpoints/snapshot-21.pt loaded.
[Trainer.py], 2020-03-25 23:28:27: evaluation starts.
[Trainer.py], 2020-03-25 23:30:16: evaluation finished.
[Training.evaluate], 2020-03-25 19:32:40: loss=4.884269714355469, acc=0.10123449683228587
[Training.evaluate], 2020-03-25 19:32:40: 0.03246325407745401
[Training.evaluate], 2020-03-25 19:32:40: 0.2276189424881333
[Trainer.py], 2020-03-26 00:00:50: checkpoints/snapshot-22.pt loaded.
[Trainer.py], 2020-03-26 00:00:50: evaluation starts.
[Trainer.py], 2020-03-26 00:02:40: evaluation finished.
[Training.evaluate], 2020-03-25 20:05:05: loss=4.792938709259033, acc=0.07581349662208565
[Training.evaluate], 2020-03-25 20:05:05: 0.02809625767708753
[Training.evaluate], 2020-03-25 20:05:05: 0.22833241908941304
[Trainer.py], 2020-03-26 00:33:16: checkpoints/snapshot-23.pt loaded.
[Trainer.py], 2020-03-26 00:33:16: evaluation starts.
[Trainer.py], 2020-03-26 00:35:05: evaluation finished.
[Training.evaluate], 2020-03-25 20:37:28: loss=4.841915607452393, acc=0.0960377640879584
[Training.evaluate], 2020-03-25 20:37:28: 0.03723054925262928
[Training.evaluate], 2020-03-25 20:37:28: 0.25201106083459024
[Trainer.py], 2020-03-26 01:05:38: checkpoints/snapshot-24.pt loaded.
[Trainer.py], 2020-03-26 01:05:38: evaluation starts.
[Trainer.py], 2020-03-26 01:07:28: evaluation finished.

[Trainer.py], 2020-03-25 21:03:14: Batch 20: loss=2.880958080291748, acc=0.38743882544861336, lr=0.000125
[Trainer.py], 2020-03-25 21:07:36: Batch 30: loss=2.8095641136169434, acc=0.3925133689839572, lr=0.000125
[Trainer.py], 2020-03-25 21:11:29: Batch 40: loss=2.4023046493530273, acc=0.4928104575163399, lr=0.000125
[Trainer.py], 2020-03-25 21:14:59: Batch 50: loss=2.7815191745758057, acc=0.4280701754385965, lr=0.000125
[Trainer.py], 2020-03-25 21:18:07: Batch 60: loss=2.707847833633423, acc=0.4239766081871345, lr=0.000125
[Trainer.py], 2020-03-25 21:18:32: Epoch finished, loss=2.723134877189757 acc=0.42430207350260424, lr=0.000125
[Trainer.py], 2020-03-25 21:18:32: training one epoch finished.
[Trainer.py], 2020-03-25 21:18:32: Epoch 17 saved.
[Trainer.py], 2020-03-25 21:20:25: start training one epoch
[Trainer.py], 2020-03-25 21:22:25: Batch 0: loss=2.8139588832855225, acc=0.4110189027201475, lr=0.000125
[Trainer.py], 2020-03-25 21:30:13: Batch 10: loss=2.821661949157715, acc=0.4059880239520958, lr=0.000125
[Trainer.py], 2020-03-25 21:35:50: Batch 20: loss=2.964096784591675, acc=0.3792822185970636, lr=0.000125
[Trainer.py], 2020-03-25 21:40:16: Batch 30: loss=2.746744394302368, acc=0.4042780748663102, lr=0.000125
[Trainer.py], 2020-03-25 21:44:08: Batch 40: loss=2.738762617111206, acc=0.4091503267973856, lr=0.000125
[Trainer.py], 2020-03-25 21:47:37: Batch 50: loss=2.633495569229126, acc=0.4368421052631579, lr=0.000125
[Trainer.py], 2020-03-25 21:50:44: Batch 60: loss=2.9194741249084473, acc=0.3567251461988304, lr=0.000125
[Trainer.py], 2020-03-25 21:51:09: Epoch finished, loss=2.7246339477243877 acc=0.42124731702973545, lr=0.000125
[Trainer.py], 2020-03-25 21:51:09: training one epoch finished.
[Trainer.py], 2020-03-25 21:51:09: Epoch 18 saved.
[Trainer.py], 2020-03-25 21:53:03: start training one epoch
[Trainer.py], 2020-03-25 21:55:01: Batch 0: loss=2.8968427181243896, acc=0.3974181650530198, lr=0.000125
[Trainer.py], 2020-03-25 22:02:47: Batch 10: loss=2.8156442642211914, acc=0.411377245508982, lr=0.000125
[Trainer.py], 2020-03-25 22:08:19: Batch 20: loss=2.7722489833831787, acc=0.4176182707993475, lr=0.000125
[Trainer.py], 2020-03-25 22:12:43: Batch 30: loss=2.554941177368164, acc=0.44171122994652406, lr=0.000125
[Trainer.py], 2020-03-25 22:16:35: Batch 40: loss=2.800907611846924, acc=0.4, lr=0.000125
[Trainer.py], 2020-03-25 22:20:04: Batch 50: loss=2.832554817199707, acc=0.3912280701754386, lr=0.000125
[Trainer.py], 2020-03-25 22:23:12: Batch 60: loss=2.603470802307129, acc=0.4473684210526316, lr=0.000125
[Trainer.py], 2020-03-25 22:23:37: Epoch finished, loss=2.7065236166356104 acc=0.4247515151253439, lr=0.000125
[Trainer.py], 2020-03-25 22:23:37: training one epoch finished.
[Trainer.py], 2020-03-25 22:23:37: Epoch 19 saved.
[Trainer.py], 2020-03-25 22:25:30: start training one epoch
[Trainer.py], 2020-03-25 22:27:29: Batch 0: loss=2.7700130939483643, acc=0.4126325495620101, lr=0.000125
[Trainer.py], 2020-03-25 22:35:16: Batch 10: loss=2.9117372035980225, acc=0.3916167664670659, lr=0.000125
[Trainer.py], 2020-03-25 22:40:45: Batch 20: loss=2.514180898666382, acc=0.4632952691680261, lr=0.000125
[Trainer.py], 2020-03-25 22:45:06: Batch 30: loss=2.7698333263397217, acc=0.4021390374331551, lr=0.000125
[Trainer.py], 2020-03-25 22:48:57: Batch 40: loss=2.9933149814605713, acc=0.3738562091503268, lr=0.000125
[Trainer.py], 2020-03-25 22:52:26: Batch 50: loss=2.667541265487671, acc=0.4105263157894737, lr=0.000125
[Trainer.py], 2020-03-25 22:55:33: Batch 60: loss=2.261319875717163, acc=0.5146198830409356, lr=0.000125
[Trainer.py], 2020-03-25 22:55:58: Epoch finished, loss=2.706067722941202 acc=0.424192387609481, lr=0.000125
[Trainer.py], 2020-03-25 22:55:58: training one epoch finished.
[Trainer.py], 2020-03-25 22:55:58: Epoch 20 saved.
[Trainer.py], 2020-03-25 22:57:51: start training one epoch
[Trainer.py], 2020-03-25 22:59:50: Batch 0: loss=2.8030099868774414, acc=0.40640848317196865, lr=6.25e-05
[Trainer.py], 2020-03-25 23:07:38: Batch 10: loss=2.7797093391418457, acc=0.4149700598802395, lr=6.25e-05
[Trainer.py], 2020-03-25 23:13:08: Batch 20: loss=2.645366668701172, acc=0.4429037520391517, lr=6.25e-05
[Trainer.py], 2020-03-25 23:17:30: Batch 30: loss=2.946340799331665, acc=0.3850267379679144, lr=6.25e-05
[Trainer.py], 2020-03-25 23:21:21: Batch 40: loss=2.6662023067474365, acc=0.4470588235294118, lr=6.25e-05
[Trainer.py], 2020-03-25 23:24:51: Batch 50: loss=2.798997163772583, acc=0.4070175438596491, lr=6.25e-05
[Trainer.py], 2020-03-25 23:27:58: Batch 60: loss=2.3454620838165283, acc=0.5029239766081871, lr=6.25e-05
[Trainer.py], 2020-03-25 23:28:23: Epoch finished, loss=2.691232064413646 acc=0.4296765789985278, lr=6.25e-05
[Trainer.py], 2020-03-25 23:28:23: training one epoch finished.
[Trainer.py], 2020-03-25 23:28:23: Epoch 21 saved.
[Trainer.py], 2020-03-25 23:30:16: start training one epoch
[Trainer.py], 2020-03-25 23:32:15: Batch 0: loss=2.739593982696533, acc=0.41931765790686953, lr=6.25e-05
[Trainer.py], 2020-03-25 23:40:04: Batch 10: loss=2.819251537322998, acc=0.39820359281437123, lr=6.25e-05
[Trainer.py], 2020-03-25 23:45:32: Batch 20: loss=2.493028163909912, acc=0.46900489396411094, lr=6.25e-05
[Trainer.py], 2020-03-25 23:49:54: Batch 30: loss=2.557701587677002, acc=0.439572192513369, lr=6.25e-05
[Trainer.py], 2020-03-25 23:53:45: Batch 40: loss=2.3567068576812744, acc=0.5006535947712418, lr=6.25e-05
[Trainer.py], 2020-03-25 23:57:15: Batch 50: loss=2.7085187435150146, acc=0.41403508771929826, lr=6.25e-05
[Trainer.py], 2020-03-26 00:00:22: Batch 60: loss=3.0310256481170654, acc=0.3830409356725146, lr=6.25e-05
[Trainer.py], 2020-03-26 00:00:47: Epoch finished, loss=2.676500103776417 acc=0.42953011121741624, lr=6.25e-05
[Trainer.py], 2020-03-26 00:00:47: training one epoch finished.
[Trainer.py], 2020-03-26 00:00:47: Epoch 22 saved.
[Trainer.py], 2020-03-26 00:02:40: start training one epoch
[Trainer.py], 2020-03-26 00:04:38: Batch 0: loss=2.739590883255005, acc=0.4248501613646842, lr=6.25e-05
[Trainer.py], 2020-03-26 00:12:24: Batch 10: loss=2.689046621322632, acc=0.4377245508982036, lr=6.25e-05
[Trainer.py], 2020-03-26 00:17:56: Batch 20: loss=2.736528158187866, acc=0.42088091353996737, lr=6.25e-05
[Trainer.py], 2020-03-26 00:22:18: Batch 30: loss=2.968139410018921, acc=0.37219251336898396, lr=6.25e-05
[Trainer.py], 2020-03-26 00:26:10: Batch 40: loss=2.632136821746826, acc=0.4392156862745098, lr=6.25e-05
[Trainer.py], 2020-03-26 00:29:39: Batch 50: loss=2.9673805236816406, acc=0.3929824561403509, lr=6.25e-05
[Trainer.py], 2020-03-26 00:32:47: Batch 60: loss=2.773721218109131, acc=0.4152046783625731, lr=6.25e-05
[Trainer.py], 2020-03-26 00:33:12: Epoch finished, loss=2.657477811451942 acc=0.43248790537113824, lr=6.25e-05
[Trainer.py], 2020-03-26 00:33:12: training one epoch finished.
[Trainer.py], 2020-03-26 00:33:12: Epoch 23 saved.
[Trainer.py], 2020-03-26 00:35:05: start training one epoch
[Trainer.py], 2020-03-26 00:37:05: Batch 0: loss=2.814638614654541, acc=0.41332411249423695, lr=6.25e-05
[Trainer.py], 2020-03-26 00:44:51: Batch 10: loss=2.7710142135620117, acc=0.4155688622754491, lr=6.25e-05
[Trainer.py], 2020-03-26 00:50:20: Batch 20: loss=2.800548791885376, acc=0.4061990212071778, lr=6.25e-05
[Trainer.py], 2020-03-26 00:54:42: Batch 30: loss=2.7126288414001465, acc=0.41497326203208557, lr=6.25e-05
[Trainer.py], 2020-03-26 00:58:33: Batch 40: loss=2.4688265323638916, acc=0.4627450980392157, lr=6.25e-05
[Trainer.py], 2020-03-26 01:02:02: Batch 50: loss=2.8067374229431152, acc=0.4105263157894737, lr=6.25e-05
[Trainer.py], 2020-03-26 01:05:10: Batch 60: loss=2.587735891342163, acc=0.4444444444444444, lr=6.25e-05
[Trainer.py], 2020-03-26 01:05:35: Epoch finished, loss=2.640859518022764 acc=0.4357930780096039, lr=6.25e-05
[Trainer.py], 2020-03-26 01:05:35: training one epoch finished.
[Trainer.py], 2020-03-26 01:05:35: Epoch 24 saved.
[Trainer.py], 2020-03-26 01:07:28: start training one epoch
[Trainer.py], 2020-03-26 01:09:27: Batch 0: loss=2.7989771366119385, acc=0.41724296911018904, lr=6.25e-05
[Trainer.py], 2020-03-26 01:17:16: Batch 10: loss=2.8332462310791016, acc=0.40059880239520956, lr=6.25e-05
[Trainer.py], 2020-03-26 01:22:52: Batch 20: loss=2.617044448852539, acc=0.4437194127243067, lr=6.25e-05[Training.evaluate], 2020-03-25 21:10:00: loss=4.925195217132568, acc=0.07812267390408457
[Training.evaluate], 2020-03-25 21:10:00: 0.03841568443927007
[Training.evaluate], 2020-03-25 21:10:00: 0.25003415767181314
[Trainer.py], 2020-03-26 01:38:11: checkpoints/snapshot-25.pt loaded.
[Trainer.py], 2020-03-26 01:38:11: evaluation starts.
[Trainer.py], 2020-03-26 01:40:00: evaluation finished.
[Training.evaluate], 2020-03-25 21:42:25: loss=4.850266933441162, acc=0.10660589870842252
[Training.evaluate], 2020-03-25 21:42:26: 0.03957437129444368
[Training.evaluate], 2020-03-25 21:42:26: 0.23411550412514737
[Trainer.py], 2020-03-26 02:10:36: checkpoints/snapshot-26.pt loaded.
[Trainer.py], 2020-03-26 02:10:36: evaluation starts.
[Trainer.py], 2020-03-26 02:12:25: evaluation finished.
[Training.evaluate], 2020-03-25 22:14:56: loss=4.9113616943359375, acc=0.08474308018184655
[Training.evaluate], 2020-03-25 22:14:56: 0.03832455478820885
[Training.evaluate], 2020-03-25 22:14:56: 0.25584575413646926
[Trainer.py], 2020-03-26 02:43:07: checkpoints/snapshot-27.pt loaded.
[Trainer.py], 2020-03-26 02:43:07: evaluation starts.
[Trainer.py], 2020-03-26 02:44:56: evaluation finished.
[Training.evaluate], 2020-03-25 22:47:24: loss=4.901190280914307, acc=0.06870027561066824
[Training.evaluate], 2020-03-25 22:47:24: 0.030056792634077185
[Training.evaluate], 2020-03-25 22:47:24: 0.22135416666666663
[Trainer.py], 2020-03-26 03:15:34: checkpoints/snapshot-28.pt loaded.
[Trainer.py], 2020-03-26 03:15:34: evaluation starts.
[Trainer.py], 2020-03-26 03:17:24: evaluation finished.
[Training.evaluate], 2020-03-25 23:19:50: loss=4.909788608551025, acc=0.08502888964618316
[Training.evaluate], 2020-03-25 23:19:50: 0.04357287885028335
[Training.evaluate], 2020-03-25 23:19:50: 0.25435674013326504
[Trainer.py], 2020-03-26 03:48:01: checkpoints/snapshot-29.pt loaded.
[Trainer.py], 2020-03-26 03:48:01: evaluation starts.
[Trainer.py], 2020-03-26 03:49:50: evaluation finished.
[Training.evaluate], 2020-03-25 23:52:17: loss=4.950507640838623, acc=0.08593593256466432
[Training.evaluate], 2020-03-25 23:52:17: 0.03999911305421577
[Training.evaluate], 2020-03-25 23:52:17: 0.25573239816563254
[Trainer.py], 2020-03-26 04:20:27: checkpoints/snapshot-30.pt loaded.
[Trainer.py], 2020-03-26 04:20:27: evaluation starts.
[Trainer.py], 2020-03-26 04:22:17: evaluation finished.
[Training.evaluate], 2020-03-26 00:24:43: loss=4.914196491241455, acc=0.08196264491171339
[Training.evaluate], 2020-03-26 00:24:43: 0.04154903339750612
[Training.evaluate], 2020-03-26 00:24:43: 0.25094035464803865
[Trainer.py], 2020-03-26 04:52:53: checkpoints/snapshot-31.pt loaded.
[Trainer.py], 2020-03-26 04:52:53: evaluation starts.
[Trainer.py], 2020-03-26 04:54:43: evaluation finished.
[Training.evaluate], 2020-03-26 00:57:10: loss=4.9390869140625, acc=0.0832161407999711
[Training.evaluate], 2020-03-26 00:57:10: 0.043827413317825074
[Training.evaluate], 2020-03-26 00:57:10: 0.2538678864523073
[Trainer.py], 2020-03-26 05:25:21: checkpoints/snapshot-32.pt loaded.
[Trainer.py], 2020-03-26 05:25:21: evaluation starts.
[Trainer.py], 2020-03-26 05:27:10: evaluation finished.

[Trainer.py], 2020-03-26 01:27:14: Batch 30: loss=2.6271896362304688, acc=0.43636363636363634, lr=6.25e-05
[Trainer.py], 2020-03-26 01:31:05: Batch 40: loss=2.6797449588775635, acc=0.42483660130718953, lr=6.25e-05
[Trainer.py], 2020-03-26 01:34:35: Batch 50: loss=2.5984060764312744, acc=0.44035087719298244, lr=6.25e-05
[Trainer.py], 2020-03-26 01:37:42: Batch 60: loss=2.29756498336792, acc=0.5058479532163743, lr=6.25e-05
[Trainer.py], 2020-03-26 01:38:07: Epoch finished, loss=2.702241753774976 acc=0.4257166496108789, lr=6.25e-05
[Trainer.py], 2020-03-26 01:38:07: training one epoch finished.
[Trainer.py], 2020-03-26 01:38:07: Epoch 25 saved.
[Trainer.py], 2020-03-26 01:40:00: start training one epoch
[Trainer.py], 2020-03-26 01:42:00: Batch 0: loss=2.9316329956054688, acc=0.3847395112955279, lr=3.125e-05
[Trainer.py], 2020-03-26 01:49:45: Batch 10: loss=2.8666393756866455, acc=0.3934131736526946, lr=3.125e-05
[Trainer.py], 2020-03-26 01:55:14: Batch 20: loss=2.9215500354766846, acc=0.3890701468189233, lr=3.125e-05
[Trainer.py], 2020-03-26 01:59:39: Batch 30: loss=2.5459139347076416, acc=0.45240641711229945, lr=3.125e-05
[Trainer.py], 2020-03-26 02:03:31: Batch 40: loss=2.497755527496338, acc=0.45359477124183006, lr=3.125e-05
[Trainer.py], 2020-03-26 02:07:00: Batch 50: loss=2.460252523422241, acc=0.47017543859649125, lr=3.125e-05
[Trainer.py], 2020-03-26 02:10:08: Batch 60: loss=2.1969189643859863, acc=0.5175438596491229, lr=3.125e-05
[Trainer.py], 2020-03-26 02:10:32: Epoch finished, loss=2.6373099538068923 acc=0.43672019385222066, lr=3.125e-05
[Trainer.py], 2020-03-26 02:10:32: training one epoch finished.
[Trainer.py], 2020-03-26 02:10:33: Epoch 26 saved.
[Trainer.py], 2020-03-26 02:12:26: start training one epoch
[Trainer.py], 2020-03-26 02:14:25: Batch 0: loss=2.815812110900879, acc=0.41724296911018904, lr=3.125e-05
[Trainer.py], 2020-03-26 02:22:13: Batch 10: loss=2.788034200668335, acc=0.4101796407185629, lr=3.125e-05
[Trainer.py], 2020-03-26 02:27:48: Batch 20: loss=2.618497133255005, acc=0.43230016313213704, lr=3.125e-05
[Trainer.py], 2020-03-26 02:32:10: Batch 30: loss=2.7494866847991943, acc=0.413903743315508, lr=3.125e-05
[Trainer.py], 2020-03-26 02:36:01: Batch 40: loss=2.373924493789673, acc=0.4745098039215686, lr=3.125e-05
[Trainer.py], 2020-03-26 02:39:30: Batch 50: loss=2.5912833213806152, acc=0.44912280701754387, lr=3.125e-05
[Trainer.py], 2020-03-26 02:42:38: Batch 60: loss=2.8432376384735107, acc=0.40350877192982454, lr=3.125e-05
[Trainer.py], 2020-03-26 02:43:03: Epoch finished, loss=2.581742737501387 acc=0.4462442968230428, lr=3.125e-05
[Trainer.py], 2020-03-26 02:43:03: training one epoch finished.
[Trainer.py], 2020-03-26 02:43:03: Epoch 27 saved.
[Trainer.py], 2020-03-26 02:44:56: start training one epoch
[Trainer.py], 2020-03-26 02:46:56: Batch 0: loss=2.780290365219116, acc=0.4142461964038728, lr=3.125e-05
[Trainer.py], 2020-03-26 02:54:43: Batch 10: loss=2.695007562637329, acc=0.41976047904191616, lr=3.125e-05
[Trainer.py], 2020-03-26 03:00:15: Batch 20: loss=2.6947546005249023, acc=0.433115823817292, lr=3.125e-05
[Trainer.py], 2020-03-26 03:04:37: Batch 30: loss=2.6603171825408936, acc=0.4288770053475936, lr=3.125e-05
[Trainer.py], 2020-03-26 03:08:28: Batch 40: loss=2.5117900371551514, acc=0.45098039215686275, lr=3.125e-05
[Trainer.py], 2020-03-26 03:11:58: Batch 50: loss=2.4874765872955322, acc=0.45789473684210524, lr=3.125e-05
[Trainer.py], 2020-03-26 03:15:06: Batch 60: loss=3.145282745361328, acc=0.35964912280701755, lr=3.125e-05
[Trainer.py], 2020-03-26 03:15:31: Epoch finished, loss=2.5994815703422303 acc=0.44241829919881653, lr=3.125e-05
[Trainer.py], 2020-03-26 03:15:31: training one epoch finished.
[Trainer.py], 2020-03-26 03:15:31: Epoch 28 saved.
[Trainer.py], 2020-03-26 03:17:24: start training one epoch
[Trainer.py], 2020-03-26 03:19:23: Batch 0: loss=2.7665209770202637, acc=0.4181650530198248, lr=3.125e-05
[Trainer.py], 2020-03-26 03:27:11: Batch 10: loss=2.820631742477417, acc=0.40119760479041916, lr=3.125e-05
[Trainer.py], 2020-03-26 03:32:41: Batch 20: loss=2.6546385288238525, acc=0.4429037520391517, lr=3.125e-05
[Trainer.py], 2020-03-26 03:37:04: Batch 30: loss=2.7236249446868896, acc=0.4235294117647059, lr=3.125e-05
[Trainer.py], 2020-03-26 03:40:56: Batch 40: loss=2.6177337169647217, acc=0.4392156862745098, lr=3.125e-05
[Trainer.py], 2020-03-26 03:44:25: Batch 50: loss=2.6433982849121094, acc=0.4473684210526316, lr=3.125e-05
[Trainer.py], 2020-03-26 03:47:32: Batch 60: loss=2.3076751232147217, acc=0.49122807017543857, lr=3.125e-05
[Trainer.py], 2020-03-26 03:47:57: Epoch finished, loss=2.608506166745746 acc=0.4403737502933719, lr=3.125e-05
[Trainer.py], 2020-03-26 03:47:57: training one epoch finished.
[Trainer.py], 2020-03-26 03:47:57: Epoch 29 saved.
[Trainer.py], 2020-03-26 03:49:50: start training one epoch
[Trainer.py], 2020-03-26 03:51:49: Batch 0: loss=2.7430715560913086, acc=0.42162286768095897, lr=3.125e-05
[Trainer.py], 2020-03-26 03:59:35: Batch 10: loss=2.7779526710510254, acc=0.3976047904191617, lr=3.125e-05
[Trainer.py], 2020-03-26 04:05:07: Batch 20: loss=2.6770708560943604, acc=0.4257748776508972, lr=3.125e-05
[Trainer.py], 2020-03-26 04:09:29: Batch 30: loss=2.629930257797241, acc=0.42780748663101603, lr=3.125e-05
[Trainer.py], 2020-03-26 04:13:21: Batch 40: loss=2.5667386054992676, acc=0.44313725490196076, lr=3.125e-05
[Trainer.py], 2020-03-26 04:16:51: Batch 50: loss=2.4144272804260254, acc=0.4666666666666667, lr=3.125e-05
[Trainer.py], 2020-03-26 04:19:58: Batch 60: loss=2.9236862659454346, acc=0.37719298245614036, lr=3.125e-05
[Trainer.py], 2020-03-26 04:20:23: Epoch finished, loss=2.5978408716027697 acc=0.442668559768318, lr=3.125e-05
[Trainer.py], 2020-03-26 04:20:23: training one epoch finished.
[Trainer.py], 2020-03-26 04:20:23: Epoch 30 saved.
[Trainer.py], 2020-03-26 04:22:17: start training one epoch
[Trainer.py], 2020-03-26 04:24:15: Batch 0: loss=2.754680871963501, acc=0.4239280774550484, lr=1.5625e-05
[Trainer.py], 2020-03-26 04:32:03: Batch 10: loss=2.783855438232422, acc=0.42095808383233535, lr=1.5625e-05
[Trainer.py], 2020-03-26 04:37:35: Batch 20: loss=2.64815616607666, acc=0.433931484502447, lr=1.5625e-05
[Trainer.py], 2020-03-26 04:41:57: Batch 30: loss=2.718541383743286, acc=0.4235294117647059, lr=1.5625e-05
[Trainer.py], 2020-03-26 04:45:48: Batch 40: loss=2.5563580989837646, acc=0.4562091503267974, lr=1.5625e-05
[Trainer.py], 2020-03-26 04:49:18: Batch 50: loss=2.27763295173645, acc=0.5052631578947369, lr=1.5625e-05
[Trainer.py], 2020-03-26 04:52:25: Batch 60: loss=2.5602924823760986, acc=0.4649122807017544, lr=1.5625e-05
[Trainer.py], 2020-03-26 04:52:50: Epoch finished, loss=2.6229865603030675 acc=0.438318876907625, lr=1.5625e-05
[Trainer.py], 2020-03-26 04:52:50: training one epoch finished.
[Trainer.py], 2020-03-26 04:52:50: Epoch 31 saved.
[Trainer.py], 2020-03-26 04:54:43: start training one epoch
[Trainer.py], 2020-03-26 04:56:42: Batch 0: loss=2.7912542819976807, acc=0.4114799446749654, lr=1.5625e-05
[Trainer.py], 2020-03-26 05:04:29: Batch 10: loss=2.743875026702881, acc=0.4221556886227545, lr=1.5625e-05
[Trainer.py], 2020-03-26 05:09:59: Batch 20: loss=2.610527753829956, acc=0.4453507340946166, lr=1.5625e-05
[Trainer.py], 2020-03-26 05:14:22: Batch 30: loss=2.4685230255126953, acc=0.46951871657754013, lr=1.5625e-05
[Trainer.py], 2020-03-26 05:18:14: Batch 40: loss=2.451292037963867, acc=0.4745098039215686, lr=1.5625e-05
[Trainer.py], 2020-03-26 05:21:44: Batch 50: loss=2.647834300994873, acc=0.4263157894736842, lr=1.5625e-05
[Trainer.py], 2020-03-26 05:24:52: Batch 60: loss=2.428924560546875, acc=0.4502923976608187, lr=1.5625e-05
[Trainer.py], 2020-03-26 05:25:17: Epoch finished, loss=2.6018426867704543 acc=0.4408317760047806, lr=1.5625e-05
[Trainer.py], 2020-03-26 05:25:17: training one epoch finished.
[Trainer.py], 2020-03-26 05:25:17: Epoch 32 saved.
[Trainer.py], 2020-03-26 05:27:10: start training one epoch
[Trainer.py], 2020-03-26 05:29:09: Batch 0: loss=2.6865451335906982, acc=0.433840479483633, lr=1.5625e-05
[Trainer.py], 2020-03-26 05:36:57: Batch 10: loss=2.5214741230010986, acc=0.46467065868263474, lr=1.5625e-05
[Trainer.py], 2020-03-26 05:42:32: Batch 20: loss=2.5521621704101562, acc=0.4453507340946166, lr=1.5625e-05[Training.evaluate], 2020-03-26 01:29:39: loss=4.908823490142822, acc=0.08177002145138922
[Training.evaluate], 2020-03-26 01:29:39: 0.038638178000058684
[Training.evaluate], 2020-03-26 01:29:39: 0.2458883796171475
[Trainer.py], 2020-03-26 05:57:50: checkpoints/snapshot-33.pt loaded.
[Trainer.py], 2020-03-26 05:57:50: evaluation starts.
[Trainer.py], 2020-03-26 05:59:39: evaluation finished.
[Training.evaluate], 2020-03-26 02:02:19: loss=4.924540042877197, acc=0.07919655815219076
[Training.evaluate], 2020-03-26 02:02:19: 0.04401815911937912
[Training.evaluate], 2020-03-26 02:02:19: 0.2521338572009213
[Trainer.py], 2020-03-26 06:30:29: checkpoints/snapshot-34.pt loaded.
[Trainer.py], 2020-03-26 06:30:29: evaluation starts.
[Trainer.py], 2020-03-26 06:32:19: evaluation finished.
[Training.evaluate], 2020-03-26 02:34:48: loss=4.933257102966309, acc=0.08148306563848222
[Training.evaluate], 2020-03-26 02:34:48: 0.04193614696022645
[Training.evaluate], 2020-03-26 02:34:48: 0.2471970822639471
[Trainer.py], 2020-03-26 07:02:59: checkpoints/snapshot-35.pt loaded.
[Trainer.py], 2020-03-26 07:02:59: evaluation starts.
[Trainer.py], 2020-03-26 07:04:48: evaluation finished.
[Training.evaluate], 2020-03-26 03:07:17: loss=4.95040225982666, acc=0.08223142674008423
[Training.evaluate], 2020-03-26 03:07:17: 0.042610006698014485
[Training.evaluate], 2020-03-26 03:07:17: 0.24229765013054827
[Trainer.py], 2020-03-26 07:35:27: checkpoints/snapshot-36.pt loaded.
[Trainer.py], 2020-03-26 07:35:27: evaluation starts.
[Trainer.py], 2020-03-26 07:37:17: evaluation finished.
[Training.evaluate], 2020-03-26 03:39:55: loss=4.918992042541504, acc=0.08412244388651809
[Training.evaluate], 2020-03-26 03:39:56: 0.04177175018334049
[Training.evaluate], 2020-03-26 03:39:56: 0.2489276139410188
[Trainer.py], 2020-03-26 08:08:06: checkpoints/snapshot-37.pt loaded.
[Trainer.py], 2020-03-26 08:08:06: evaluation starts.
[Trainer.py], 2020-03-26 08:09:55: evaluation finished.
[Training.evaluate], 2020-03-26 04:12:32: loss=4.9185404777526855, acc=0.08015942611795178
[Training.evaluate], 2020-03-26 04:12:32: 0.04113309705693645
[Training.evaluate], 2020-03-26 04:12:32: 0.24690527448869748
[Trainer.py], 2020-03-26 08:40:43: checkpoints/snapshot-38.pt loaded.
[Trainer.py], 2020-03-26 08:40:43: evaluation starts.
[Trainer.py], 2020-03-26 08:42:32: evaluation finished.
[Training.evaluate], 2020-03-26 04:45:04: loss=4.907492160797119, acc=0.0844692735671652
[Training.evaluate], 2020-03-26 04:45:05: 0.04449673837346886
[Training.evaluate], 2020-03-26 04:45:05: 0.24976638633026294
[Trainer.py], 2020-03-26 09:13:15: checkpoints/snapshot-39.pt loaded.
[Trainer.py], 2020-03-26 09:13:15: evaluation starts.
[Trainer.py], 2020-03-26 09:15:04: evaluation finished.
[Training.evaluate], 2020-03-26 05:17:32: loss=4.965190410614014, acc=0.07858473067771268
[Training.evaluate], 2020-03-26 05:17:32: 0.04311981776412953
[Training.evaluate], 2020-03-26 05:17:32: 0.2457627118644068
[Trainer.py], 2020-03-26 09:45:42: checkpoints/snapshot-40.pt loaded.
[Trainer.py], 2020-03-26 09:45:42: evaluation starts.
[Trainer.py], 2020-03-26 09:47:32: evaluation finished.
[Training.train], 2020-03-25 06:28:05: 0.009415252358482944
[Training.train], 2020-03-25 06:28:05: 0.25746670207264744
[Training.train], 2020-03-25 07:04:38: 0.026307558412429093
[Training.train], 2020-03-25 07:04:38: 0.2952947696975001
[Training.train], 2020-03-25 07:40:27: 0.036698280146862855
[Training.train], 2020-03-25 07:40:27: 0.30575697971405924
[Training.train], 2020-03-25 08:14:10: 0.036687300740635975
[Training.train], 2020-03-25 08:14:10: 0.2999603983631324
[Training.train], 2020-03-25 08:50:45: 0.04533188993016907
[Training.train], 2020-03-25 08:50:45: 0.32615497612926914
[Training.train], 2020-03-25 09:27:42: 0.042566801755977955
[Training.train], 2020-03-25 09:27:42: 0.3082731065279981
[Training.train], 2020-03-25 10:04:16: 0.05197063438609465
[Training.train], 2020-03-25 10:04:16: 0.34693697664169243
[Training.train], 2020-03-25 11:55:10: 0.0448816190288835
[Training.train], 2020-03-25 11:55:10: 0.32489829487876165
[Training.train], 2020-03-25 12:28:11: 0.054236482209385886
[Training.train], 2020-03-25 12:28:11: 0.34046741190122953
[Training.train], 2020-03-25 13:00:59: 0.04982583552329481
[Training.train], 2020-03-25 13:00:59: 0.32973973327066564
[Training.train], 2020-03-25 13:33:23: 0.047011234933503045
[Training.train], 2020-03-25 13:33:23: 0.31265053163367207
[Training.train], 2020-03-25 14:05:59: 0.05608740259341181
[Training.train], 2020-03-25 14:05:59: 0.35774171441902514
[Training.train], 2020-03-25 14:38:32: 0.05418028976163193
[Training.train], 2020-03-25 14:38:32: 0.33322568333284397
[Training.train], 2020-03-25 15:11:07: 0.05635250451016786
[Training.train], 2020-03-25 15:11:07: 0.34878574340457746
[Training.train], 2020-03-25 15:43:32: 0.053981267159587974
[Training.train], 2020-03-25 15:43:32: 0.34624700891087656
[Training.train], 2020-03-25 16:16:05: 0.0596422238826959
[Training.train], 2020-03-25 16:16:05: 0.3631851753960912
[Training.train], 2020-03-25 16:48:35: 0.061291281867068774
[Training.train], 2020-03-25 16:48:35: 0.3751963475682262
[Training.train], 2020-03-25 17:21:13: 0.05911481425063016
[Training.train], 2020-03-25 17:21:13: 0.3657096703135325
[Training.train], 2020-03-25 17:53:40: 0.06478336679457498
[Training.train], 2020-03-25 17:53:40: 0.37446777272059906
[Training.train], 2020-03-25 18:26:02: 0.062039371599481315
[Training.train], 2020-03-25 18:26:02: 0.3747945768282662
[Training.train], 2020-03-25 18:58:26: 0.06474906376002158
[Training.train], 2020-03-25 18:58:26: 0.37191951828462333
[Training.train], 2020-03-25 19:30:50: 0.067576750774673
[Training.train], 2020-03-25 19:30:50: 0.3787371512481644
[Training.train], 2020-03-25 20:03:15: 0.07072955084726096
[Training.train], 2020-03-25 20:03:15: 0.39321407082373316
[Training.train], 2020-03-25 20:35:38: 0.07217826667965385
[Training.train], 2020-03-25 20:35:38: 0.3932236233649936
[Training.train], 2020-03-25 21:08:11: 0.07099362832699199
[Training.train], 2020-03-25 21:08:11: 0.3966151905788493
[Training.train], 2020-03-25 21:40:36: 0.07090386681699863
[Training.train], 2020-03-25 21:40:36: 0.380300314419206
[Training.train], 2020-03-25 22:13:07: 0.08231844314292427
[Training.train], 2020-03-25 22:13:07: 0.41046690610569525
[Training.train], 2020-03-25 22:45:34: 0.07619228121067166
[Training.train], 2020-03-25 22:45:34: 0.39304176702108906
[Training.train], 2020-03-25 23:18:01: 0.07301374940352925
[Training.train], 2020-03-25 23:18:01: 0.3842898704046549
[Training.train], 2020-03-25 23:50:27: 0.07757819027118883
[Training.train], 2020-03-25 23:50:27: 0.40410175160637263
[Training.train], 2020-03-26 00:22:53: 0.07478520369719123
[Training.train], 2020-03-26 00:22:53: 0.389917348092253
[Training.train], 2020-03-26 00:55:21: 0.0754590190181169
[Training.train], 2020-03-26 00:55:21: 0.3952395636021908
[Training.train], 2020-03-26 01:27:49: 0.07792076738937913
[Training.train], 2020-03-26 01:27:49: 0.3980792105379092
[Training.train], 2020-03-26 02:00:29: 0.07749590458760688
[Training.train], 2020-03-26 02:00:29: 0.401382610227206
[Training.train], 2020-03-26 02:32:58: 0.07481908102990995
[Training.train], 2020-03-26 02:32:58: 0.39940971763358446
[Training.train], 2020-03-26 03:05:27: 0.0793125612238901
[Training.train], 2020-03-26 03:05:27: 0.3966314738403254
[Training.train], 2020-03-26 03:38:06: 0.07846966055232542
[Training.train], 2020-03-26 03:38:06: 0.4055711205315887
[Training.train], 2020-03-26 04:10:42: 0.07558492486106352
[Training.train], 2020-03-26 04:10:42: 0.40279367315197934
[Training.train], 2020-03-26 04:43:15: 0.07823606987864232
[Training.train], 2020-03-26 04:43:15: 0.40480241734385547
[Training.train], 2020-03-26 05:15:42: 0.07987248601477723
[Training.train], 2020-03-26 05:15:42: 0.40312591722923397

[Trainer.py], 2020-03-26 05:46:54: Batch 30: loss=2.4948806762695312, acc=0.46737967914438505, lr=1.5625e-05
[Trainer.py], 2020-03-26 05:50:45: Batch 40: loss=2.296046733856201, acc=0.4993464052287582, lr=1.5625e-05
[Trainer.py], 2020-03-26 05:54:14: Batch 50: loss=2.505201816558838, acc=0.4473684210526316, lr=1.5625e-05
[Trainer.py], 2020-03-26 05:57:21: Batch 60: loss=2.8317313194274902, acc=0.39766081871345027, lr=1.5625e-05
[Trainer.py], 2020-03-26 05:57:46: Epoch finished, loss=2.622587282742773 acc=0.4378345183052917, lr=1.5625e-05
[Trainer.py], 2020-03-26 05:57:46: training one epoch finished.
[Trainer.py], 2020-03-26 05:57:46: Epoch 33 saved.
[Trainer.py], 2020-03-26 05:59:39: start training one epoch
[Trainer.py], 2020-03-26 06:01:38: Batch 0: loss=2.8123457431793213, acc=0.41055786076532963, lr=1.5625e-05
[Trainer.py], 2020-03-26 06:09:25: Batch 10: loss=2.7304158210754395, acc=0.42095808383233535, lr=1.5625e-05
[Trainer.py], 2020-03-26 06:15:00: Batch 20: loss=2.582385540008545, acc=0.43882544861337686, lr=1.5625e-05
[Trainer.py], 2020-03-26 06:19:30: Batch 30: loss=2.521181583404541, acc=0.45240641711229945, lr=1.5625e-05
[Trainer.py], 2020-03-26 06:23:23: Batch 40: loss=2.476966142654419, acc=0.4562091503267974, lr=1.5625e-05
[Trainer.py], 2020-03-26 06:26:53: Batch 50: loss=2.743974208831787, acc=0.41403508771929826, lr=1.5625e-05
[Trainer.py], 2020-03-26 06:30:00: Batch 60: loss=2.764655828475952, acc=0.40058479532163743, lr=1.5625e-05
[Trainer.py], 2020-03-26 06:30:25: Epoch finished, loss=2.6045105147456367 acc=0.44185028547888405, lr=1.5625e-05
[Trainer.py], 2020-03-26 06:30:25: training one epoch finished.
[Trainer.py], 2020-03-26 06:30:25: Epoch 34 saved.
[Trainer.py], 2020-03-26 06:32:19: start training one epoch
[Trainer.py], 2020-03-26 06:34:19: Batch 0: loss=2.813157081604004, acc=0.4103273397879207, lr=1.5625e-05
[Trainer.py], 2020-03-26 06:42:05: Batch 10: loss=2.655385971069336, acc=0.4311377245508982, lr=1.5625e-05
[Trainer.py], 2020-03-26 06:47:36: Batch 20: loss=2.7157254219055176, acc=0.42414355628058725, lr=1.5625e-05
[Trainer.py], 2020-03-26 06:51:58: Batch 30: loss=2.495950937271118, acc=0.4641711229946524, lr=1.5625e-05
[Trainer.py], 2020-03-26 06:55:52: Batch 40: loss=2.816615581512451, acc=0.40784313725490196, lr=1.5625e-05
[Trainer.py], 2020-03-26 06:59:22: Batch 50: loss=2.494056463241577, acc=0.45614035087719296, lr=1.5625e-05
[Trainer.py], 2020-03-26 07:02:30: Batch 60: loss=2.4550867080688477, acc=0.4619883040935672, lr=1.5625e-05
[Trainer.py], 2020-03-26 07:02:55: Epoch finished, loss=2.5996594977757286 acc=0.4416871174014213, lr=1.5625e-05
[Trainer.py], 2020-03-26 07:02:55: training one epoch finished.
[Trainer.py], 2020-03-26 07:02:55: Epoch 35 saved.
[Trainer.py], 2020-03-26 07:04:48: start training one epoch
[Trainer.py], 2020-03-26 07:06:47: Batch 0: loss=2.8057117462158203, acc=0.4119409866297833, lr=7.8125e-06
[Trainer.py], 2020-03-26 07:14:33: Batch 10: loss=2.6674602031707764, acc=0.4341317365269461, lr=7.8125e-06
[Trainer.py], 2020-03-26 07:20:06: Batch 20: loss=2.6693127155303955, acc=0.4363784665579119, lr=7.8125e-06
[Trainer.py], 2020-03-26 07:24:29: Batch 30: loss=2.8035638332366943, acc=0.40855614973262033, lr=7.8125e-06
[Trainer.py], 2020-03-26 07:28:21: Batch 40: loss=2.4830496311187744, acc=0.4549019607843137, lr=7.8125e-06
[Trainer.py], 2020-03-26 07:31:51: Batch 50: loss=2.466705799102783, acc=0.4473684210526316, lr=7.8125e-06
[Trainer.py], 2020-03-26 07:34:59: Batch 60: loss=2.251579523086548, acc=0.5029239766081871, lr=7.8125e-06
[Trainer.py], 2020-03-26 07:35:24: Epoch finished, loss=2.591190088835974 acc=0.44383141463985515, lr=7.8125e-06
[Trainer.py], 2020-03-26 07:35:24: training one epoch finished.
[Trainer.py], 2020-03-26 07:35:24: Epoch 36 saved.
[Trainer.py], 2020-03-26 07:37:17: start training one epoch
[Trainer.py], 2020-03-26 07:39:17: Batch 0: loss=2.676206588745117, acc=0.4432918395573997, lr=7.8125e-06
[Trainer.py], 2020-03-26 07:47:03: Batch 10: loss=2.8256776332855225, acc=0.4, lr=7.8125e-06
[Trainer.py], 2020-03-26 07:52:35: Batch 20: loss=2.8502144813537598, acc=0.38743882544861336, lr=7.8125e-06
[Trainer.py], 2020-03-26 07:56:57: Batch 30: loss=2.593599796295166, acc=0.4459893048128342, lr=7.8125e-06
[Trainer.py], 2020-03-26 08:00:58: Batch 40: loss=2.6905055046081543, acc=0.42483660130718953, lr=7.8125e-06
[Trainer.py], 2020-03-26 08:04:30: Batch 50: loss=2.8725268840789795, acc=0.37543859649122807, lr=7.8125e-06
[Trainer.py], 2020-03-26 08:07:37: Batch 60: loss=2.513136863708496, acc=0.4590643274853801, lr=7.8125e-06
[Trainer.py], 2020-03-26 08:08:02: Epoch finished, loss=2.613024419262296 acc=0.44039942443605934, lr=7.8125e-06
[Trainer.py], 2020-03-26 08:08:02: training one epoch finished.
[Trainer.py], 2020-03-26 08:08:02: Epoch 37 saved.
[Trainer.py], 2020-03-26 08:09:56: start training one epoch
[Trainer.py], 2020-03-26 08:11:55: Batch 0: loss=2.7326958179473877, acc=0.42254495159059474, lr=7.8125e-06
[Trainer.py], 2020-03-26 08:19:44: Batch 10: loss=2.775426149368286, acc=0.42095808383233535, lr=7.8125e-06
[Trainer.py], 2020-03-26 08:25:19: Batch 20: loss=2.695563554763794, acc=0.43800978792822187, lr=7.8125e-06
[Trainer.py], 2020-03-26 08:29:43: Batch 30: loss=2.6679725646972656, acc=0.42780748663101603, lr=7.8125e-06
[Trainer.py], 2020-03-26 08:33:36: Batch 40: loss=2.6616010665893555, acc=0.4366013071895425, lr=7.8125e-06
[Trainer.py], 2020-03-26 08:37:06: Batch 50: loss=2.4597394466400146, acc=0.4807017543859649, lr=7.8125e-06
[Trainer.py], 2020-03-26 08:40:14: Batch 60: loss=2.4184627532958984, acc=0.48830409356725146, lr=7.8125e-06
[Trainer.py], 2020-03-26 08:40:39: Epoch finished, loss=2.6003096817977847 acc=0.44301302113247637, lr=7.8125e-06
[Trainer.py], 2020-03-26 08:40:39: training one epoch finished.
[Trainer.py], 2020-03-26 08:40:39: Epoch 38 saved.
[Trainer.py], 2020-03-26 08:42:32: start training one epoch
[Trainer.py], 2020-03-26 08:44:32: Batch 0: loss=2.6691110134124756, acc=0.43407100046104197, lr=7.8125e-06
[Trainer.py], 2020-03-26 08:52:20: Batch 10: loss=2.818962574005127, acc=0.4, lr=7.8125e-06
[Trainer.py], 2020-03-26 08:57:53: Batch 20: loss=2.637755870819092, acc=0.42495921696574224, lr=7.8125e-06
[Trainer.py], 2020-03-26 09:02:17: Batch 30: loss=2.5901803970336914, acc=0.44278074866310163, lr=7.8125e-06
[Trainer.py], 2020-03-26 09:06:09: Batch 40: loss=2.310302495956421, acc=0.4954248366013072, lr=7.8125e-06
[Trainer.py], 2020-03-26 09:09:39: Batch 50: loss=2.730257749557495, acc=0.41754385964912283, lr=7.8125e-06
[Trainer.py], 2020-03-26 09:12:46: Batch 60: loss=2.5027408599853516, acc=0.4678362573099415, lr=7.8125e-06
[Trainer.py], 2020-03-26 09:13:11: Epoch finished, loss=2.6138588909118896 acc=0.4392452672695332, lr=7.8125e-06
[Trainer.py], 2020-03-26 09:13:11: training one epoch finished.
[Trainer.py], 2020-03-26 09:13:11: Epoch 39 saved.
[Trainer.py], 2020-03-26 09:15:05: start training one epoch
[Trainer.py], 2020-03-26 09:17:05: Batch 0: loss=2.8166720867156982, acc=0.40640848317196865, lr=7.8125e-06
[Trainer.py], 2020-03-26 09:24:50: Batch 10: loss=2.677039623260498, acc=0.4281437125748503, lr=7.8125e-06
[Trainer.py], 2020-03-26 09:30:20: Batch 20: loss=2.8091623783111572, acc=0.399673735725938, lr=7.8125e-06
[Trainer.py], 2020-03-26 09:34:45: Batch 30: loss=2.593291997909546, acc=0.44171122994652406, lr=7.8125e-06
[Trainer.py], 2020-03-26 09:38:36: Batch 40: loss=2.414414644241333, acc=0.477124183006536, lr=7.8125e-06
[Trainer.py], 2020-03-26 09:42:06: Batch 50: loss=2.5306475162506104, acc=0.45087719298245615, lr=7.8125e-06
[Trainer.py], 2020-03-26 09:45:13: Batch 60: loss=2.531993865966797, acc=0.4502923976608187, lr=7.8125e-06
[Trainer.py], 2020-03-26 09:45:38: Epoch finished, loss=2.600124096823117 acc=0.4413250421522571, lr=7.8125e-06
[Trainer.py], 2020-03-26 09:45:38: training one epoch finished.
[Trainer.py], 2020-03-26 09:45:38: Epoch 40 saved.
[Training.evaluate], 2020-03-27 01:53:43: 0.034904671179405385
[Training.evaluate], 2020-03-27 01:53:43: 0.18055868438837575
[Trainer.py], 2020-03-27 06:19:59: /Users/jin/Desktop/VS_Code/im2latex-master-original/checkpoints/snapshot-40.pt loaded.
[Trainer.py], 2020-03-27 06:19:59: evaluation starts.
[Trainer.py], 2020-03-27 06:23:42: evaluation finished.
